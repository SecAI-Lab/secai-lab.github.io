- title: "Fool Me If You Can: On the Robustness of Binary Code Similarity Detection Models against Semantics-preserving Transformations (To appear)"
  image: asmfooler.png
  description: "Binary analysis plays an essential role in cybersecurity, facilitating reverse engineering to reveal the inner workings of programs in the absence of source code. Traditional approaches, such as static and dynamic analysis, extract valuable insights from stripped binaries, but often demand substantial expertise and manual effort. Recent advances in deep learning have opened promising opportunities to enhance binary analysis by capturing latent features and disclosing underlying code semantics. Despite the growing number of binary analysis models based on machine learning, their robustness to adversarial code transformations remains underexplored. In this work, we evaluate the robustness of deep learning models for the task of binary code similarity detection (BCSD) under semantics-preserving transformations. The unique nature of machine instructions presents distinct challenges compared to the typical input perturbations found in other domains. To achieve our goal, we introduce asmFooler, a system that evaluates the resilience of BCSD models using a diverse set of adversarial code transformations that preserve functional semantics. We construct a dataset of 9,565 binary variants from 620 baseline samples by applying eight semantics-preserving transformations across six representative BCSD models. Our major findings highlight several key insights: i) model robustness highly relies on the design of the processing pipeline, including code pre-processing, model architecture, and internal feature selection, which collectively determine how code semantics are captured; ii) the effectiveness of adversarial transformations is bounded by a transformation budget, shaped by model-specific constraints such as input size limits and the expressive capacity of semantically equivalent instructions; iii) well-crafted adversarial transformations can be highly effective, even when introducing minimal perturbations; and iv) such transformations disrupt the model’s ability to recognize and focus on semantically significant instructions." 
  authors: Jiyong Uhm, Minseok Kim, Michalis Polychronakis and Hyungjoon Koo
  link: 
    url: 
    display: In ACM International Conference on Foundations of Software Engineering, 2026 (FSE '26)
  github: https://zenodo.org/records/17116512
  highlight: 1
  news2:

- title: "UnPII: Unlearning Personally Identifiable Information with Quantifiable Exposure Risk (To appear)"
  image: overview_pii_unlearning_new.png
  description: "The ever-increasing adoption of Large Language Models in critical sectors like finance, healthcare, and government raises privacy concerns regarding the handling of sensitive Personally Identifiable Information (PII) during training. In response, regulations such as European Union’s General Data Protection Regulation (GDPR) mandate the deletion of PII upon requests, underscoring the need for reliable and cost-effective data removal solutions. Machine unlearning has emerged as a promising direction for selectively forgetting data points. However, existing unlearning techniques typically apply a uniform forgetting strategy that neither accounts for the varying privacy risks posed by different PII attributes nor reflects associated business risks. In this work, we propose UnPII, the first PII-centric unlearning approach that prioritizes forgetting based on the risk of individual or combined PII attributes. To this end, we introduce the PII risk index (PRI), a composite metric that incorporates multiple dimension of risk factors: identifiability, sensitivity, usability, linkability, permanency, exposability, and compliancy. The PRI enables a nuanced evaluation of privacy risks associated with PII exposures and can be tailored to align with organizational privacy policies. To support realistic assessment, we systematically construct a synthetic PII dataset (e.g., 1,700 PII instances) that simulates realistic exposure scenarios. UnPII seamlessly integrates with established unlearning algorithms, such as Gradient Ascent, Negative Preference Optimization, and Direct Preference Optimization, without modifying their underlying principles. Our experimental results demonstrate that UnPII achieves the improvements of ac- curacy up to 11.8%, utility up to 6.3%, and generalizability up to 12.4%, respectively, while incurring a modest fine-tuning overhead of 27.5% on average during unlearning."
  authors: Intae Jeon, Yujeong Kwon, and Hyungjoon Koo
  link: 
    url: 
    arXiv: https://arxiv.org/abs/2601.01786
    display: In the Software Engineering in Practice track of the International Conference on Software Engineering, 2026 (ICSE-SEIP '26)
  github: 
  highlight: 1
  news2:

- title: "A Deep Dive into Function Inlining and its Security Implications for ML-based Binary Analysis (To appear)"
  image: INLINING.jpg
  description: "A function inlining optimization is a widely used transformation in modern compilers, which replaces a call site with the callee’s body in need. While this transformation improves performance, it significantly impacts static features such as machine instructions and control flow graphs, which are crucial to binary analysis. Yet, despite its broad impact, the security impact of function inlining remains underexplored to date. In this paper, we present the first comprehensive study of function inlining through the lens of machine learning-based binary analysis. To this end, we dissect the inlining decision pipeline within the LLVM’s cost model and explore the combinations of the compiler options that aggressively promote the function inlining ratio beyond standard optimization levels, which we term extreme inlining. We focus on five ML-assisted security tasks (e.g., binary reversing), using 18 unique models to systematically evaluate their robustness under extreme inlining scenarios. Our extensive experiments reveal several significant findings: i) function inlining, though a benign transformation in intent, can (in)directly affect ML model behaviors, being potentially exploited by evading discriminative or generative ML models; ii) ML models relying on static features can be highly sensitive to inlining; iii) subtle compiler settings can be leveraged to deliberately craft evasive binary variants; and iv) inlining ratios vary substantially across applications and build configurations, undermining assumptions of consistency in training and evaluation of ML models." 
  authors: Omar Abusabha, Jiyong Uhm, Tamer Abuhmed, and Hyungjoon Koo
  link: 
    url: 
    display: In Network and Distributed System Security Symposium, 2026 (NDSS ’26)
    arXiv: https://arxiv.org/abs/2512.14045
  github: https://zenodo.org/records/17759528
  highlight: 1
  news2:

- title: "Rescuing the Unpoisoned: Efficient Defense against Knowledge Corruption Attacks on RAG Systems"
  image: RAGDEFENDER.png
  description: "Large language models (LLMs) are reshaping numerous facets of our daily lives, leading widespread adoption as web-based services. Despite their versatility, LLMs face notable challenges, such as generating hallucinated content and lacking access to up-to-date information. Lately, to address such limitations, Retrieval-Augmented Generation (RAG) has emerged as a promising direction by generating responses grounded in external knowledge sources. A typical RAG system consists of i) a retriever that probes a group of relevant passages from a knowledge base and ii) a generator that formulates a response based on the retrieved content. However, as with other AI systems, recent studies demonstrate the vulnerability of RAG, such as knowledge corruption attacks by injecting misleading information. In response, several defense strategies have been proposed, including having LLMs inspect the retrieved passages individually or fine-tuning robust retrievers. While effective, such approaches often come with substantial computational costs. In this work, we introduce RAGDefender, a resource-efficient defense mechanism against knowledge corruption (i.e., by data poisoning) attacks in practical RAG deployments. RAGDefender operates during the post-retrieval phase, leveraging lightweight machine learning techniques to detect and filter out adversarial content without requiring additional model training or inference. Our empirical evaluations show that RAGDefender consistently outperforms existing state-of-the-art defenses across multiple models and adversarial scenarios: e.g., RAGDefender reduces the attack success rate (ASR) against the Gemini model from 0.89 to as low as 0.02, compared to 0.69 for RobustRAG and 0.24 for Discern-and-Answer when adversarial passages outnumber legitimate ones by a factor of four (4x)." 
  authors: Minseok Kim, Hankook Lee, and Hyungjoon Koo
  link: 
    arXiv: https://arxiv.org/abs/2511.01268
    url: https://www.acsac.org/2025/program/papers/
    display: In the 41th Annual Computer Security Applications Conference, 2025 (ACSAC '25)
  github: https://github.com/SecAI-Lab/RAGDefender
  slides: "https://for8821.synology.me:5001/d/s/16BGaQNRoWR8OFAlNSY6gRmPyaS3w4Pk/lJtYfuJC-2uKX62QiEDvY6gkODfn2Mh1-r7BAovUt0Qw"
  highlight: 1
  news2:

- title: "A Decade-long Landscape of Advanced Persistent Threats: Longitudinal Analysis and Global Trends"
  image: APT.png
  description: "An advanced persistent threat (APT) refers to a covert and long-term cyberattack, typically conducted by state-sponsored actors, targeting critical sectors and often remaining undetected for long periods. In response, collective intelligence from around the globe collaborates to identify and trace surreptitious activities, generating substantial documentation on APT campaigns publicly available on the web. While a multitude of prior works predominantly focus on specific aspects of APT cases, such as detection, evaluation, cyber threat intelligence, and dataset creation, limited attention has been devoted to revisiting and investigating these scattered dossiers in a longitudinal manner. The objective of our study lies in filling the gap by offering a macro perspective, connecting key insights and global trends in the past APT attacks. We systematically analyze six reliable sources - three focused on technical reports and another three on threat actors - examining 1,509 APT dossiers (i.e., totaling 24,215 pages) spanning from 2014 to 2023 (a decade), and identifying 603 unique APT groups in the world. To efficiently unearth relevant information, we employ a hybrid methodology that combines rule-based information retrieval with large-language-model-based search techniques. Our longitudinal analysis reveals shifts in threat actor activities, global attack vectors, changes in targeted sectors, and the relationships between cyberattacks and significant events, such as elections or wars, which provides insights into historical patterns in APT evolution. Over the past decade, 154 countries have been affected, primarily using malicious documents and spear phishing as the dominant initial infiltration vectors, and a noticeable decline in zero-day exploitation since 2016. Furthermore, we present our findings through interactive visualization tools, such as an APT map or a flow diagram, to facilitate intuitive understanding of the global patterns and trends in APT activities." 
  authors: Shakhzod Yuldoshkhujaev, Mijin Jeon, Doowon Kim, Nick Nikiforakis, and Hyungjoon Koo
  link: 
    arXiv: https://arxiv.org/abs/2509.07457
    url: https://dl.acm.org/doi/10.1145/3719027.3765085
    display: In the 32nd ACM Conference on Computer and Communications Security, 2025 (CCS '25)
  link2:
    url: https://www.sigsac.org/ccs/CCS2025/awards/
    display: Distinguished Paper Award 
  highlight: 1
  github: "https://zenodo.org/records/16869733"
  slides: "https://kevinkoo001.github.io/assets/pdf/ccs25-apt-slides.pdf"
  news2:

- title: "BOOTKITTY: A Stealthy Bootkit-Rootkit Against Modern Operating Systems"
  image: 
  description: "Bootkits and rootkits are among the most elusive and persistent forms of malware, subverting system defenses by operating at the lowest levels of system architecture. Bootkits compromise the firmware or bootloader, allowing them to manipulate the boot sequence and gain control before security mechanisms initialize. Meanwhile, rootkits embed themselves within the OS kernel, stealthily conceal malicious activities, and maintain long-term persistence. Despite their critical implications for security, these threats remain underexplored due to the technical complexity involved in their study, the scarcity of real-world samples, and the challenges posed by defense-in-depth security in modern OSes. In this paper, we introduce BOOTKITTY, a hybrid bootkit-rootkit capable of circumventing modern security features in multiple OS platforms, across Windows, Linux, and Android. We explore critical firmware and bootloader vulnerabilities that can lead to a low-level compromise, demonstrating techniques that bypass advanced security protections by breaking the chain of trust. Our study addresses technical challenges such as exploiting UEFI drivers, manipulating kernel memory, and evading advanced mitigations in the boot process, and provides actionable insights. Our systematic evaluations show that BOOTKITTY reveals critical weaknesses in contemporary security mechanisms, highlighting the need for better security design that offers holistic (low-level) protection." 
  authors: Junho Lee, Jihoon Kwon, HyunA Seo, Myeongyeol Lee, Hyungyu Seo, Jinho Jung, and Hyungjoon Koo
  link: 
    url: https://www.usenix.org/system/files/woot25-lee.pdf
    display: In the 19th USENIX WOOT Conference on Offensive Technologies, 2025 (WOOT '25)
  highlight: 0
  news2:

- title: "Evaluating the Effectiveness and Robustness of Visual Similarity-based Phishing Detection Models"
  image: 
  description: "Phishing attacks pose a significant threat to Internet users,
  with cybercriminals elaborately replicating the visual appearance of legitimate websites to deceive victims. Visual
  similarity-based detection systems have emerged as an effective countermeasure, but their effectiveness and robustness
  in real-world scenarios have been underexplored. In this paper, we comprehensively scrutinize and evaluate the effectiveness and robustness of popular visual similarity-based
  anti-phishing models using a large-scale dataset of 451k realworld phishing websites. Our analyses of the effectiveness reveal that while certain visual similarity-based models achieve
  high accuracy on curated datasets in the experimental settings,
  they exhibit notably low performance on real-world datasets,
  highlighting the importance of real-world evaluation. Furthermore, we find that the attackers evade the detectors mainly
  in three ways: (1) directly attacking the model pipelines, (2)
  mimicking benign logos, and (3) employing relatively simple
  strategies such as eliminating logos from screenshots. To statistically assess the resilience and robustness of existing models against adversarial attacks, we categorize the strategies
  attackers employ into visible and perturbation-based manipulations and apply them to website logos. We then evaluate
  the models’ robustness using these adversarial samples. Our
  findings reveal potential vulnerabilities in several models,
  emphasizing the need for more robust visual similarity techniques capable of withstanding sophisticated evasion attempts.
  We provide actionable insights for enhancing the security of
  phishing defense systems, encouraging proactive actions."
  authors: Fujiao Ji, Kiho Lee, Hyungjoon Koo, Wenhao You, Euijin Choo, Hyoungshick Kim, and Doowon Kim
  link: 
    url: https://www.usenix.org/system/files/conference/usenixsecurity25/sec25cycle1-prepub-483-ji.pdf
    display: In the 34nd USENIX Conference on Security Symposium, 2025 (USENIX '25)
  highlight: 0
  news2:

- title: "An Empirical Study of Black-box based Membership Inference Attacks on a Real-World Dataset"
  image: 
  description: "The recent advancements in artificial intelligence drive the
  widespread adoption of Machine-Learning-as-a-Service platforms, which
  offers valuable services. However, these pervasive utilities in the cloud
  environment unavoidably encounter security and privacy issues. In particular, a membership inference attack (MIA) poses 
  a threat by recognizing the presence of a data sample in a training set for the target model.
  Although prior MIA approaches underline privacy risks repeatedly by
  demonstrating experimental results with standard benchmark datasets
  such as MNIST and CIFAR. However, the effectiveness of such techniques
  on a real-world dataset remains questionable. We are the first to perform
  an in-depth empirical study on black-box based MIAs that hold realistic assumptions, including six metric-based and three classifier-based
  MIAs with the high-dimensional image dataset that consists of identification (ID) cards and driving licenses. Additionally, we introduce the
  Siamese-based MIA that shows similar or better performance than the
  state-of-the-art approaches and suggest training a shadow model with
  autoencoder-based reconstructed images. Our major findings show that
  the performance of MIA techniques against too many features may be
  degraded; the MIA configuration or a sample’s properties can impact the
  accuracy of membership inference on members and non-members."
  authors: Yujeong Kwon, Simon S. Woo, and Hyungjoon Koo
  link: 
    url: https://link.springer.com/chapter/10.1007/978-3-031-87496-3_9
    display: International Symposium on Foundations and Practice of Security, 2024 (FPS '24)
  highlight: 0
  news2:
  
- title: "R2I: A Relative Readability Metric for Decompiled Code"
  image: r2i.png
  description: "Decompilation is a process of converting a low-level machine code snippet back into a high-level programming
  language such as C. It serves as a basis to aid reverse engineers in comprehending the contextual semantics of
  the code. In this respect, commercial decompilers like Hex-Rays have made significant strides in improving
  the readability of decompiled code over time. While previous work has proposed the metrics for assessing the
  readability of source code, including identifiers, variable names, function names, and comments, those metrics
  are unsuitable for measuring the readability of decompiled code primarily due to i) the lack of rich semantic
  information in the source and ii) the presence of erroneous syntax or inappropriate expressions. In response,
  to the best of our knowledge, this work first introduces R2I, the Relative Readability Index, a specialized metric
  tailored to evaluate decompiled code in a relative context quantitatively. In essence, R2I can be computed by
  i) taking code snippets across different decompilers as input and ii) extracting pre-defined features from an
  abstract syntax tree. For the robustness of R2I, we thoroughly investigate the enhancement efforts made by
  existing decompilers and academic research to promote code readability, identifying 31 features to yield a
  reliable index collectively. Besides, we conducted a user survey to capture subjective factors such as one’s
  coding styles and preferences. Our empirical experiments demonstrate that R2I is a versatile metric capable of
  representing the relative quality of decompiled code (e.g., obfuscation, decompiler updates) and being well
  aligned with human perception in our survey."
  authors: Haeun Eom, Dohee Kim, Sori Lim, Hyungjoon Koo, and Sungjae Hwang
  link:
    url: https://dl.acm.org/doi/10.1145/3643744
    display: In the ACM International Conference on the Foundations of Software Engineering, 2024 (FSE '24)
  highlight: 1
  news2:
  github: https://github.com/e0mh4/R2I

- title: "BinAdapter: Leveraging Continual Learning for Inferring Function Symbol Names in a Binary"
  image: binadapter.png
  description: "Binary reverse engineering is crucial to gain insights into the inner workings of a stripped binary. Yet, it is challenging to read the original semantics from a binary code snippet because of the unavailability of high-level information in the source, such as function names, variable names, and types. Recent advancements in deep learning show the possibility of recovering such vanished information with a well-trained model from a pre-defined dataset. Albeit a static model’s notable performance, it can hardly cope with ever-increasing data stream (e.g., compiled binaries) by nature. The two viable approaches for ceaseless learning are retraining the whole dataset from scratch and fine-tuning a pre-trained model; however, retraining suffers from large computational overheads and fine-tuning from performance degradation (i.e., catastrophic forgetting). Lately, continual learning (CL) tackles the problem of handling incremental data in security domains (e.g., network intrusion detection, malware detection) using reasonable resources while maintaining performance in practice. In this paper, we focus on how CL assists the improvement of a generative model that predicts a function symbol name from a series of machine instructions. To this end, we introduce BinAdapter, a system that can infer function names from an incremental dataset without performance degradation from an original dataset by leveraging CL techniques. Our major finding shows that incremental tokens in the source (i.e., machine instructions) or the target (i.e., function names) largely affect the overall performance of a CL-enabled model. Accordingly, BinAdapter adopts three built-in approaches: i) inserting adapters in case of no incremental tokens in both the source and target, ii) harnessing multilingual neural machine translation (M-NMT) and fine-tuning the source embeddings with i) in case of incremental tokens in the source, and iii) fine-tuning target embeddings with ii) in case of incremental tokens in both. To demonstrate the effectiveness of BinAdapter, we evaluate the above three scenarios using incremental datasets with or without a set of new tokens (e.g., unseen machine instructions or function names), spanning across different architectures and optimization levels. Our empirical results show that BinAdapter outperforms the state-of-the-art CL techniques for an F1 of up to 24.3% or a Rouge-l of 21.5% in performance."
  authors: Nozima Murodova and Hyungjoon Koo
  link:
    url: https://dl.acm.org/doi/10.1145/3634737.3645006
    display: In the 19th ACM Asia Conference on Computer and Communications Security, 2024 (ASIACCS ’24) 
  highlight: 0
  news2:
  github: https://github.com/SecAI-Lab/BinAdapter

- title: "ToolPhet: Inference of Compiler Provenance from Stripped Binaries with Emerging Compilation Toolchains"
  image: 
  description: "Identifying compiler toolchain provenance serves as a basis for both benign and malicious binary analyses. A wealth of prior studies mostly focuses on the inference of a popular compiler toolchain for C and C++ languages from stripped binaries that are built with GCC or clang. Lately, the popularity of an emerging compiler is on the rise such as Rust, Go, and Nim programming languages that complement the downsides of C and C++ (e.g., security), which little has been explored on them. The main challenge arises when applying previous inference techniques for toolchain provenance because some emerging compilation toolchains adopt the same backend of traditional compilers. In this paper, we propose ToolPhet, an effective end-to-end BERT-based system for deducing the provenance of both traditional and emerging compiler toolchains. To this end, we thoroughly study the characteristics of both an emerging toolchain and an executable binary that is generated by that toolchain. We introduce two separate downstream tasks for the compiler toolchain inference with a (BERT-based) fine-tuning process, which produces i) a toolchain classification model, and ii) a binary code similarity detection model. Our findings show that the classification model (i) may not suffice when producing a binary with the existing backend like Nim, which we adopt the detection model (ii) that can infer underlying code semantics. We evaluate ToolPhet with the previous work including one signature-based tool and four machine-learning-based approaches, demonstrating its effectiveness by achieving higher F1 scores with the binaries compiled with emerging compilation toolchains."
  authors: Hohyeon Jang, Nozima Murodova, and Hyungjoon Koo
  link:
    url: https://ieeexplore.ieee.org/document/10401926
    display: IEEE Access (2024)
  highlight: 0
  news2:

- title: "Demystifying the Regional Phishing Landscape in South Korea"
  image: 
  description: "The ever-increasing phishing campaigns around the globe have been one of main threats in cyber security. In response, the global anti-phishing entity (APWG) collectively maintains the up-to-date blacklist database (e.g., eCrimeX) against phishing campaigns, and so do modern browsers (e.g., Google Safe Browsing). However, our finding reveals that such a mutual assistance system has been remaining a blind spot when detecting geolocation-based phishing campaigns. In this paper, we focus on phishing campaigns against the web portal service with the largest number of users (42 million) in South Korea. We harvest 1,558 phishing URLs from varying resources in the span of a full year, which only a small fraction (3.8%) have been detected by eCrimeX despite a wide spectrum of active fraudulence cases. We demystify three pervasive types of phishing campaigns in South Korea: i) sophisticated phishing campaigns with varying adversarial tactics such as a proxy configuration, ii) phishing campaigns against a secondhand online market, and iii) phishing campaigns against a non-specific target. Our finding shows that a phishing kit that supports automating the whole phishing campaigns is prevalent. Besides, we frequently observe a hit-and-run scam where a phishing campaign is immediately inaccessible right after victimization is complete, each of which is tailored to a single potential victim over a new channel like a messenger. As part of mitigation efforts, we promptly provide regional phishing information to APWG, and immediately lock down a victim’s account to prevent further damages."
  authors: Hyunjun Park, Kyungchan Lim, Doowon Kim, Donghyun Yu, and Hyungjoon Koo
  link:
    url: 
    display: IEEE Access (2023)
  highlight: 0
  news2:

- title: "BENZENE: A Practical Root Cause Analysis System with an Under-Constrained State Mutation"
  image: benzene.png
  description: "Fuzzing has demonstrated great success in bug discovery and plays a crucial role in software testing today. Despite the increasing popularity of fuzzing, automated root cause analysis (RCA) has drawn less attention. One of the recent advances in RCA is crash-based statistical debugging, which leverages the behavioral differences in program execution between crash-triggered and non-crashing inputs. Hence, obtaining non-crashing behaviors close to the original crash is crucial but challenging with previous approaches (e.g., fuzzing). In this paper, we present BENZENE, a practical end-to-end RCA system that facilitates a fully automated crash diagnosis. To this end, we introduce a novel technique, called under-constrained state mutation, that generates both crashing and non-crashing behaviors for effective and efficient RCA. We design and implement the BENZENE prototype, and evaluate it with 60 vulnerabilities in the wild. Our empirical results demonstrate that BENZENE not only surpasses in performance (i.e., root cause ranking), but also achieves superior results in both speed (4.6 times faster) and memory footprint (31.4 times less) on average than prior approaches." 
  authors: Younggi Park, Hwiwon Lee, Jinho Jung, Hyungjoon Koo, and Huy Kang Kim
  link:
    url: https://www.computer.org/csdl/proceedings-article/sp/2024/313000a074/1RjEaJVHT4k
    display: In the 45th IEEE Symposium on Security and Privacy, 2024 (S&P ’24)
  link2:
    url: https://sp2024.ieee-security.org/awards.html
    display: Distinguished Paper Award 
  highlight: 1
  github: https://github.com/zer0fall/BENZENE
  news2:

- title: "Binary Code Representation with Well-balanced Instruction Normalization"
  image:
  description: "The recovery of contextual meanings on a machine code is required by a wide range of binary analysis applications, such as bug discovery, malware analysis, and code clone detection. To accomplish this, advancements on binary code analysis borrow the techniques from natural language processing to automatically infer the underlying semantics of a binary, rather than replying on manual analysis. One of crucial pipelines in this process is instruction normalization, which helps to reduce the number of tokens and to avoid an out-of-vocabulary (OOV) problem. However, existing approaches often substitutes operands with a common token (e.g., callee target → FOO), inevitably resulting in the loss of important information. In this paper, we introduce well-balanced instruction normalization (WIN), a novel approach that retains rich code information while minimizing the downsides of code normalization. With large swaths of binary code, our finding shows that the instruction distribution follows Zipf’s Law like a natural language, a function conveys contextually meaningful information, and the same instruction at different positions may require diverse code representations. To show the effectiveness of WIN, we present DeepSemantic that harnesses the BERT architecture with two training phases: pre-training for generic assembly code representation, and fine-tuning for building a model tailored to a specialized task. We define a downstream task of binary code similarity detection, which requires underlying code semantics. Our experimental results show that our binary similarity model with WIN outperforms two state-of-the-art binary similarity tools, DeepBinDiff and SAFE, with an average improvement of 49.8% and 15.8%, respectively."
  authors: Hyungjoon Koo, Soyeon Park, Daejin Choi, and Taesoo Kim
  link:
    url: https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6287639
    display: IEEE Access (2023)
    arXiv: https://arxiv.org/abs/2106.05478
  highlight: 0
  news2:

- title: "SmartMark: Software Watermarking Scheme for Smart Contracts"
  image: smartmark.png
  description: "A smart contract is a self-executing program on a blockchain to ensure an immutable and transparent agreement without the involvement of intermediaries. Despite its growing popularity for many blockchain platforms like Ethereum, no technical means is available even when a smart contract requires to be protected from being copied. One of promising directions to claim a software ownership is software watermarking. However, applying existing software watermarking techniques is challenging because of the unique properties of a smart contract, such as a code size constraint, non-free execution cost, and no support for dynamic allocation under a virtual machine environment. This paper introduces a novel software watermarking scheme, dubbed SMARTMARK, aiming to protect the ownership of a smart contract against a pirate activity. SMARTMARK builds the control flow graph of a target contract runtime bytecode, and locates a collection of bytes that are randomly elected for representing a watermark. We implement a full-fledged prototype for Ethereum, applying SMARTMARK to 27,824 unique smart contract bytecodes. Our empirical results demonstrate that SMARTMARK can effectively embed a watermark into a smart contract and verify its presence, meeting the requirements of credibility and imperceptibility while incurring an acceptable performance degradation. Besides, our security analysis shows that SMARTMARK is resilient against viable watermarking corruption attacks; e.g., a large number of dummy opcodes are needed to disable a watermark effectively, resulting in producing an illegitimate smart contract clone that is not economical."
  authors: Taeyoung Kim, Yunhee Jang, Chanjong Lee, Hyungjoon Koo, and Hyoungshick Kim
  link:
    url: https://dl.acm.org/doi/abs/10.1109/ICSE48619.2023.00035
    display: In the 45th IEEE/ACM International Conference on Software Engineering, 2023 (ICSE ’23)
  highlight: 
  news2:

- title: "A Transformer-based Function Symbol Name Inference Model from an Assembly Language for Binary Reversing"
  image: asmdepictor.png
  description: "Reverse engineering of a stripped binary has a wide range of applications, yet it is challenging mainly due to the lack of contextually useful information within. Once debugging symbols (e.g., variablenames, types, function names) are discarded, recovering such informationis not technically viable with traditional approacheslike static or dynamic binary analysis. We focus on a functionsymbol name recovery, which allows a reverse engineer to gaina quick overview of an unseen binary. The key insight is that awell-developed program labels a meaningful function name thatdescribes its underlying semantics well. In this paper, we presentAsmDepictor, the Transformer-based framework that generates afunction symbol name from a set of assembly codes (i.e., machine instructions),which consists of three major components: binary coderefinement, model training, and inference. To this end, we conductsystematic experiments on the effectiveness of code refinement thatcan enhance an overall performance. We introduce the per-layerpositional embedding and Unique-softmax for AsmDepictor sothat both can aid to capture a better relationship between tokens.Lastly, we devise a novel evaluation metric tailored for a short descriptionlength, the Jaccard* score. Our empirical evaluation showsthat the performance of AsmDepictor by far surpasses that of thestate-of-the-art models up to around 400%. The best AsmDepictormodel achieves an F1 of 71.5 and Jaccard* of 75.4."
  authors: Hyunjin Kim, Jinyeong Bak, Kyunghyun Cho, and Hyungjoon Koo
  link:
    url: https://dl.acm.org/doi/abs/10.1145/3579856.3582823
    display: In the 18th ACM Asia Conference on Computer and Communications Security, 2023 (ASIACCS ’23)
  highlight: 1
  news2:

- title: "Practical Binary Code Similarity Detection with BERT-based Transferable Similarity Learning"
  image: binshot.png
  description: "Binary code similarity detection serves as a basis for a wide spectrum of applications, including software plagiarism, malware classification, and known vulnerability discovery. However, the inference of contextual meanings of a binary is challenging due to the absence of semantic information available in source codes. Recent advances leverage the benefits of a deep learning architecture into a better understanding of underlying code semantics and the advantages of the Siamese architecture into better code similarity detection. In this paper, we propose BinShot, a BERT-based similarity learning architecture that is highly transferable for effective binary code similarity detection. We tackle the problem of detecting code similarity with one-shot learning (a special case of few-shot learning). To this end, we adopt a weighted distance vector with a binary cross entropy as a loss function on top of BERT. With the prototype implementation of BinShot, our experimental results demonstrate the effectiveness, transferability, and practicality of BinShot, which is robust to detecting the similarity of previously unseen functions.We show that BinShot outperforms the previous state-of-the-art approaches for binary code similarity detection." 
  authors: Sunwoo Ahn, Seonggwan Ahn, Hyungjoon Koo, and Yunheung Paek
  link:
    url: https://dl.acm.org/doi/abs/10.1145/3564625.3567975 
    display: In the 38th Annual Computer Security Applications Conference (ACSAC ’22)
  highlight: 
  news2:
  github: "https://github.com/asw0316/binshot"
  slides: "https://kevinkoo001.github.io/assets/pdf/binshot-acsac22-slides.pdf"
- title: "DeView: Confining Progressive Web Applications by Debloating Web APIs"
  image: 
  description: "A progressive web application (PWA) becomes an attractive option for building universal applications based on feature-rich web application programming interfaces (Web APIs). While flexible, such vast APIs inevitably bring a significant increase in an API attack surface, which commonly corresponds to a functionality that is neither needed nor wanted by the application. A promising approach to reduce the API attack surface is software debloating, a technique wherein an unused functionality is programmatically removed from an application or API. Unfortunately, debloating PWAs is challenging given the monolithic design and non-deterministic execution of a modern web browser. In this paper, we present DeView, a practical approach that reduces the attack surface of a PWA by blocking unnecessary but accessible web APIs. DeView tackles the challenges of PWA debloating by i) record-and-replay web API profiling that identifies needed web APIs on an app-by-app basis by replaying (recorded) browser interactions and ii) compiler-assisted browser debloating that eliminates the entry functions of corresponding web APIs from the mapping between web API and its entry point at a binary level. Our evaluation shows the effectiveness and practicality of DeView. DeView successfully eliminates 91.8% of accessible web APIs while i) maintaining original functionalities and ii) preventing 76.3% of known exploits on average."
  authors: ChangSeok Oh, Sangho Lee, Chenxiong Qian, Hyungjoon Koo, and Wenke Lee
  link:
    url: https://dl.acm.org/doi/10.1145/3564625.3567987
    display: In the 38th Annual Computer Security Applications Conference (ACSAC ’22)
  highlight: 0
  github: https://github.com/shivamidow/deview
  news2:

- title: "IoTivity Packet Parser for Encrypted Messages in Internet of Things"
  image: 
  description: The Internet of Things (IoT) market has been ever-growing because both the demand of smart lives and the number of mobile users keep increasing. On the other hand, IoT device manufacturers tend to employ proprietary operating systems and network protocols, which may lead device interoperability issues. The Open Connectivity Foundation (OCF) has established a standard protocol for seamless IoT communication. IoTivity is one of reference implementations that conforms to the OCF specification. IoTivity utilizes both Datagram Transport Layer Security (DTLS) and Constrained Application Protocol (CoAP) to support a lightweight and secure communication. Although a packet analysis tool like Wireshark offers a feature to decrypt messages over TLS or DTLS by feeding a session key that a Web browser records, it cannot be directly applied to IoTivity because it lacks such a tracing functionality. In this paper, we develop an IoTivity Packet Parser (IPP) for encrypted CoAP messages tailored to IoTivity. To this end, we modify IoTivity source code to extract required keys, and implement an automated CoAP parser that parses each field with the collected keys, which allows for further debugging in a handy way.
  authors: Hyeonah Jung, Hyungjoon Koo, and Jaehoon (Paul) Jeong 
  link:
    url: https://www.icact.org/
    display: In the 24th International Conference on Advanced Communications Technology (ICACT ’22)
  highlight: 0
  news2:

- title: "Software Watermarking via a Binary Function Relocation"
  image: softmark.png
  description: The ease of reproducibility of digital artifacts raises a growing concern in copyright infringement; in particular, for a software product. Software watermarking is one of the promising techniques to verify the owner of licensed software by embedding a digital fingerprint. Developing an ideal software watermark scheme is challenging because i) unlike digital media watermarking, software watermarking has to preserve the original code semantics after inserting software watermark, and ii) it requires well-balanced properties of credibility, resiliency, capacity, imperceptibility, and efficiency. We present SoftMark, a software watermarking system that leverages a function relocation where the order of functions implicitly encodes a hidden identifier. By design, SoftMark does not introduce additional structures (i.e., codes, blocks, or subroutines), being robust in unauthorized detection, while maintaining a negligible performance overhead and reasonable capacity. With various strategies against viable attacks (i.e., static binary re-instrumentation), we tackle the limitations of previous reordering-based approaches. Our empirical results demonstrate the practicality and effectiveness by successful embedding and extraction of various watermark values.
  authors: Honggoo Kang, Yonghwi Kwon, Sangjin Lee, and Hyungjoon Koo
  link:
    url: https://dl.acm.org/doi/abs/10.1145/3485832.3488027
    display: In the 37th Annual Computer Security Applications Conference (ACSAC ’21)
  highlight: 0
  news2: 
  
- title: "A Look Back on a Function Identification Problem"
  image: #lookback.png
  description: A function recognition problem serves as a basis for further binary analysis and many applications. Although common challenges for function detection are well known, prior works have repeatedly claimed a noticeable result with a high precision and recall. In this paper, we aim to fill the void of what has been overlooked or misinterpreted by closely looking into the previous datasets, metrics, and evaluations with varying case studies. Our major findings are that i) a common corpus like GNU utilities is insufficient to represent the effectiveness of function identification, ii) it is difficult to claim, at least in the current form, that an ML-oriented approach is scientifically superior to deterministic ones like IDA or Ghidra, iii) the current metrics may not be reasonable enough to measure all function detection cases, iv) the capability of recognizing functions depends on each tool’s strategic or peculiar choice. We perform re-evaluation of existing approaches on our own dataset, demonstrating that not a single state-of-the-art tool dominates all the others. In conclusion, a function detection problem has not yet been fully addressed, and we need a better methodology and metric to make advances in the field of function identification.
  authors: Hyungjoon Koo, Soyeon Park, and Taesoo Kim
  link:
    url: https://dl.acm.org/doi/abs/10.1145/3485832.3488018
    display: In the 37th Annual Computer Security Applications Conference (ACSAC ’21)
  highlight: 0
  news2: 
 
- title: "Slimium: Debloating the Chromium Browser with Feature Subsetting"
  image: #slimium.png
  description: Today, a web browser plays a crucial role in offering a broad spectrum of web experiences. The most popular browser, Chromium, has become an extremely complex application to meet ever-increasing user demands, exposing unavoidably large attack vectors due to its large code base. Code debloating attracts attention as a means of reducing such a potential attack surface by eliminating unused code. However, it is very challenging to perform sophisticated code removal without breaking needed functionalities because Chromium operates on a large number of closely connected and complex components, such as a renderer and JavaScript engine. In this paper, we present Slimium, a debloating framework for a browser (i.e., Chromium) that harnesses a hybrid approach for a fast and reliable binary instrumentation. The main idea behind Slimium is to determine a set of features as a debloating unit on top of a hybrid (i.e., static, dynamic, heuristic) analysis, and then leverage feature subsetting to code debloating. It aids in i) focusing on securityoriented features, ii) discarding unneeded code simply without complications, and iii) reasonably addressing a non-deterministic path problem raised from code complexity. To this end, we generate a feature-code map with a relation vector technique and prompt webpage profiling results. Our experimental results demonstrate the practicality and feasibility of Slimium for 40 popular websites, as on average it removes 94 CVEs (61.4%) by cutting down 23.85 MB code (53.1%) from defined features (21.7% of the whole) in Chromium. 
  authors: Chenxiong Qian, Hyungjoon Koo, Changseok Oh, Taesoo Kim, and Wenke Lee
  link:
    url: https://dl.acm.org/doi/pdf/10.1145/3372297.3417866
    display: In the 27th ACM Conference on Computer and Communications Security (CCS ’20)
  highlight: 0
  news2:

- title: "Compiler-assisted Code Randomization"
  image: ccr.png
  description: Despite decades of research on software diversification, only address space layout randomization has seen widespread adoption. Code randomization, an effective defense against return-oriented programming exploits, has remained an academic exercise mainly due to i) the lack of a transparent and streamlined deployment model that does not disrupt existing software distribution norms, and ii) the inherent incompatibility of program variants with error reporting, whitelisting, patching, and other operations that rely on code uniformity. In this work we present compiler-assisted code randomization (CCR), a hybrid approach that relies on compiler–rewriter cooperation to enable fast and robust fine-grained code randomization on end-user systems, while maintaining compatibility with existing software distribution models. The main concept behind CCR is to augment binaries with a minimal set of transformationassisting metadata, which i) facilitate rapid fine-grained code transformation at installation or load time, and ii) form the basis for reversing any applied code transformation when needed, to maintain compatibility with existing mechanisms that rely on referencing the original code. We have implemented a prototype of this approach by extending the LLVM compiler toolchain, and developing a simple binary rewriter that leverages the embedded metadata to generate randomized variants using basic block reordering. The results of our experimental evaluation demonstrate the feasibility and practicality of CCR, as on average it incurs a modest file size increase of 11.46% and a negligible runtime overhead of 0.28%, while it is compatible with link-time optimization and control flow integrity.
  authors: Hyungjoon Koo, Yaohui Chen, Long Lu, Vasileios P. Kemerlis, and Michalis Polychronakis
  link:
    url: https://ieeexplore.ieee.org/document/8418619
    display: In the 39th IEEE Symposium on Security & Privacy, 2018 (S&P ’18)
  highlight: 0
  github: https://github.com/kevinkoo001/CCR
  
- title: "Defeating Zombie Gadgets by Re-randomizing Code Upon Disclosure"
  image: 
  authors: Micah Morton, Hyungjoon Koo, Forrest Li, Kevin Z. Snow, Michalis Polychronakis, and Fabian Monrose
  description: Over the past few years, return-oriented programming (ROP) attacks have emerged as a prominent strategy for hijacking control of software. The full power and flexibility of ROP attacks was recently demonstrated using just-intime ROP tactics (JIT-ROP), whereby an adversary repeatedly leverages a memory disclosure vulnerability to identify useful instruction sequences and compile them into a functional ROP payload at runtime. Since the advent of just-in-time code reuse attacks, numerous proposals have surfaced for mitigating them, the most practical of which involve the re-randomization of code at runtime or the destruction of gadgets upon their disclosure. Even so, several avenues exist for performing code inference, which allows JIT-ROP attacks to infer values at specific code locations without directly reading the memory contents of those bytes. This is done by reloading code of interest or implicitly determining the state of randomized code. These so-called “zombie gadgets” completely undermine defenses that rely on destroying code bytes once they are read. To mitigate these attacks, we present a low-overhead, binary-compatible defense which ensures an attacker is unable to execute gadgets that were identified through code reloading or code inference. We have implemented a prototype of the proposed defense for closed-source Windows binaries, and demonstrate that our approach effectively prevents zombie gadget attacks with negligible runtime overhead.
  link:
    url: https://link.springer.com/chapter/10.1007/978-3-319-62105-0_10
    display: In the 9th International Symposium on Engineering Secure Software and Systems, 2017 (ESSoS ’17)
  highlight: 0
  news2:


- title: "Return to the Zombie Gadgets: Undermining Destructive Code Reads via Code-Inference Attacks"
  image: 
  authors: Kevin Z. Snow, Roman Rogowski, Jan Werner, Hyungjoon Koo, Fabian Monrose and Michalis Polychronakis
  description: The concept of destructive code reads is a new defensive strategy that prevents code reuse attacks by coupling finegrained address space layout randomization with a mitigation for online knowledge gathering that destroys potentially useful gadgets as they are disclosed by an adversary. The intuition is that by destroying code as it is read, an adversary is left with no usable gadgets to reuse in a control-flow hijacking attack. In this paper, we examine the security of this new mitigation. We show that while the concept initially appeared promising, there are several unforeseen attack tactics that render destructive code reads ineffective in practice. Specifically, we introduce techniques for leveraging constructive reloads, wherein multiple copies of native code are loaded into a process address space (either side-by-side or one-afteranother). Constructive reloads allow the adversary to disclose one code copy, destroying it in the process, then use another code copy for their code reuse payload. For situations where constructive reloads are not viable, we show that an alternative, and equally powerful, strategy exists - leveraging code association via implicit reads, which allows an adversary to undo in-place code randomization by inferring the layout of code that follows already disclosed bytes. As a result, the implicitly learned code is not destroyed, and can be used in the adversary’s code reuse attack. We demonstrate the effectiveness of our techniques with concrete instantiations of these attacks against popular applications. In light of our successes, we argue that the code inference strategies presented herein paint a cautionary tale for defensive approaches whose security blindly rests on the perceived inability to undo the application of in-place randomization 
  link:
    url: https://ieeexplore.ieee.org/document/7546544
    display: In the 37th IEEE Symposium on Security and Privacy, 2016 (S&P ’16)
  highlight: 0
  news2:

- title: "Juggling the Gadgets: Binary-level Code Randomization using Instruction Displacement"
  image: 
  authors: Hyungjoon Koo and Michalis Polychronakis
  description: Code diversification is an effective mitigation against return-oriented programming attacks, which breaks the assumptions of attackers about the location and structure of useful instruction sequences, known as “gadgets.” Although a wide range of code diversification techniques of varying levels of granularity exist, most of them rely on the availability of source code, debug symbols, or the assumption of fully precise code disassembly, limiting their practical applicability for the protection of closed-source third-party applications. In-place code randomization has been proposed as an alternative binary-compatible diversification technique that is tolerant of partial disassembly coverage, in the expense though of leaving some gadgets intact, at the disposal of attackers. Consequently, the possibility of constructing robust ROP payloads using only the remaining non-randomized gadgets is still open. In this paper we present instruction displacement, a code diversification technique based on static binary instrumentation that does not rely on complete code disassembly coverage. Instruction displacement aims to improve the randomization coverage and entropy of existing binary-level code diversification techniques by displacing any remaining non-randomized gadgets to random locations. The results of our experimental evaluation demonstrate that instruction displacement reduces the number of non-randomized gadgets in the extracted code regions from 15.04% for standalone in-place code randomization, to 2.77% for the combination of both techniques. At the same time, the additional indirection introduced due to displacement incurs a negligible runtime overhead of 0.36% on average for the SPEC CPU2006 benchmarks.
  link:
    url: https://dl.acm.org/doi/abs/10.1145/2897845.2897863
    display: In the 11th ACM Asia Conference on Computer and Communications Security, 2016 (ASIACCS ’16)
  highlight: 0
  github: https://github.com/kevinkoo001/ropf
  news2:
  
- title: "Identifying Traffic Differentiation in Mobile Networks"
  image: 
  authors: Arash Molavi Kakhki, Abbas Razaghpanah, Anke Li, Hyungjoon Koo, Rajeshkumar Golani, David Choffnes, Phillipa Gill, and Alan Mislove
  description: Traffic differentiation—giving better (or worse) performance to certain classes of Internet traffic—is a well-known but poorly understood traffic management policy. There is active discussion on whether and how ISPs should be allowed to differentiate Internet traffic [8, 21], but little data about current practices to inform this discussion. Previous work attempted to address this problem for fixed line networks; however, there is currently no solution that works in the more challenging mobile environment. In this paper, we present the design, implementation, and evaluation of the first system and mobile app for identifying traffic differentiation for arbitrary applications in the mobile environment (i.e., wireless networks such as cellular and WiFi, used by smartphones and tablets). The key idea is to use a VPN proxy to record and replay the network traffic generated by arbitrary applications, and compare it with the network behavior when replaying this traffic outside of an encrypted tunnel. We perform the first known testbed experiments with actual commercial shaping devices to validate our system design and demonstrate how it outperforms previous work for detecting differentiation. We released our app and collected differentiation results from 12 ISPs in 5 countries. We find that differentiation tends to affect TCP traffic (reducing rates by up to 60%) and that interference from middleboxes (including video-transcoding devices) is pervasive. By exposing such behavior, we hope to improve transparency for users and help inform future policies.
  link:
    url: https://dl.acm.org/doi/10.1145/2815675.2815691
    display: In the 15th ACM Internet Measurement Conference, 2015 (IMC ’15)
  highlight: 0
  news2:
